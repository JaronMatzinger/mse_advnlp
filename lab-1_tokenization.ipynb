{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Byte-Pair Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freqs = {'low_' : 5, 'lowest_' : 2, 'newer_' : 6, 'wider_' : 3, 'new_' : 2}\n",
    "\n",
    "vocab = set(\"\".join(word_freqs.keys()))\n",
    "vocab = list(vocab)\n",
    "\n",
    "splits = {word: [c for c in word] for word in word_freqs.keys()}\n",
    "\n",
    "def compute_pair_freqs(splits, word_freqs):\n",
    "    \"\"\"Count occurrences of adjacent symbol pairs in coprus.\"\"\"\n",
    "    pair_freqs = defaultdict(int)\n",
    "    for word, freq in word_freqs.items():\n",
    "        split = splits[word]\n",
    "        if len(split) == 1:\n",
    "            continue\n",
    "        for i in range(len(split) - 1):\n",
    "            pair = (split[i], split[i + 1])\n",
    "            pair_freqs[pair] += freq\n",
    "    return pair_freqs\n",
    "\n",
    "def most_freq_pair(pair_freqs):\n",
    "    \"\"\"Find the most frequent adjacent pair.\"\"\"\n",
    "    if not pair_freqs:\n",
    "        return ('', '')\n",
    "    \n",
    "    best_pair = max(pair_freqs, key=pair_freqs.get)\n",
    "    return best_pair\n",
    "\n",
    "def merge_pair(a, b, splits, word_freqs):\n",
    "    \"\"\"Merge most frequent pair into a single token in all words.\"\"\"\n",
    "    for word in word_freqs:\n",
    "        split = splits[word]\n",
    "        if len(split) == 1:\n",
    "            continue\n",
    "\n",
    "        new_split = []\n",
    "        i = 0\n",
    "        while i < len(split):\n",
    "            if i < len(split) - 1 and split[i] == a and split[i + 1] == b:\n",
    "                new_split.append(a + b)\n",
    "                i += 2\n",
    "            else:\n",
    "                new_split.append(split[i])\n",
    "                i += 1\n",
    "\n",
    "        splits[word] = new_split\n",
    "    return splits\n",
    "\n",
    "merges = {}\n",
    "\n",
    "num_merges = 8\n",
    "for _ in range(num_merges):\n",
    "    pair_freqs = compute_pair_freqs(splits, word_freqs)\n",
    "    best_pair = most_freq_pair(pair_freqs)\n",
    "\n",
    "    if best_pair == ('', ''):\n",
    "        break\n",
    "\n",
    "    a, b = best_pair\n",
    "    splits = merge_pair(a, b, splits, word_freqs)\n",
    "    merges[best_pair] = a + b\n",
    "    vocab.append(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merges: {('e', 'r'): 'er', ('er', '_'): 'er_', ('n', 'e'): 'ne', ('ne', 'w'): 'new', ('l', 'o'): 'lo', ('lo', 'w'): 'low', ('new', 'er_'): 'newer_', ('low', '_'): 'low_'}\n",
      "Final vocabulary: ['i', 'l', 'o', '_', 'e', 't', 'w', 's', 'n', 'd', 'r', 'er', 'er_', 'ne', 'new', 'lo', 'low', 'newer_', 'low_']\n"
     ]
    }
   ],
   "source": [
    "print('Merges:', merges)\n",
    "print('Final vocabulary:', vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
