{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6Pcr40HVO5h"
      },
      "source": [
        "# AdvNLP BERTlab\n",
        "\n",
        "## Session goal\n",
        "In this session we'll be using pre-trained BERT to predict missing words in English and German and to tackle a cloze test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thuc9WpVVO5j"
      },
      "source": [
        "We're only using pre-trained BERT, so you don't need a GPU to run this notebook.\n",
        "To avoid platform-specific problems, we recommend you run this notebook on Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1HQM_4RVO5k",
        "outputId": "fd7d40cc-9c63-4a19-b913-95bf731e471a"
      },
      "outputs": [],
      "source": [
        "#!pip install pytorch-pretrained-bert\n",
        "import torch\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe61kjixVO5l"
      },
      "source": [
        "Choose a model below. Be sure to use a **multilingual** model if you wish to use German or anything else other than English."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChpqUCQOVO5m",
        "outputId": "6121619d-1593-40fc-845f-9fe3b8cb7009"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 644831.45B/s]\n",
            "100%|██████████| 407873900/407873900 [01:34<00:00, 4329004.05B/s] \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): BertLayerNorm()\n",
              "      )\n",
              "      (decoder): Linear(in_features=768, out_features=30522, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "#model = 'bert-base-multilingual-uncased'\n",
        "#model = 'bert-base-multilingual-cased'\n",
        "model = 'bert-base-uncased'\n",
        "#model = 'bert-large-uncased'\n",
        "do_lower_case = True\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(model, do_lower_case=do_lower_case)\n",
        "language_model = BertForMaskedLM.from_pretrained(model)\n",
        "language_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFnwZ5yxVO5n"
      },
      "source": [
        "Enter your text below. Populate the **candidates** list if you want BERT to choose out of a set of predefined words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "z8RrDiHqVO5n"
      },
      "outputs": [],
      "source": [
        "def ask_BERT(text, candidates, language_model, tokenizer):\n",
        "    tokenized_text = tokenizer.tokenize(text)\n",
        "    masked_index = []\n",
        "\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "      if token == '_':\n",
        "        masked_index.append(i)\n",
        "        tokenized_text[i]= '[MASK]'\n",
        "\n",
        "    candidates_ids = tokenizer.convert_tokens_to_ids(candidates)\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "    \n",
        "    segments_ids = [0] * len(tokenized_text)\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "    segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "    predictions = language_model(tokens_tensor, segments_tensors)\n",
        "\n",
        "    if len(candidates) > 0:\n",
        "      predictions_candidates = predictions[0, masked_index, candidates_ids]\n",
        "      probs = (predictions_candidates.softmax(dim=0))\n",
        "\n",
        "      probabilities = (probs.detach().numpy())\n",
        "      tokens = tokenizer.convert_ids_to_tokens(candidates_ids)\n",
        "\n",
        "      tuple_list = ([(x, probabilities[i]) for i, x in enumerate(tokens)])\n",
        "\n",
        "      sorted_tuple_list = sorted(tuple_list, key=lambda x: x[1], reverse=True)\n",
        "      print (text)\n",
        "      print (sorted_tuple_list)\n",
        "\n",
        "      answer_idx = torch.argmax(predictions_candidates).item()\n",
        "      print(f'The most likely word is \"{candidates[answer_idx]}\".')\n",
        "\n",
        "    else:\n",
        "      predictions_candidates = predictions[0, masked_index, range(predictions.shape[-1])]\n",
        "      probs = (predictions_candidates.softmax(dim=0))\n",
        "      max_prob = probs.max(dim=0)\n",
        "      threshold = 0.01\n",
        "      indices = ((np.where(probs>threshold)))\n",
        "\n",
        "      probabilities = ((probs[probs>threshold]).detach().numpy())\n",
        "      tokens = tokenizer.convert_ids_to_tokens(indices[0])\n",
        "\n",
        "      tuple_list = ([(x, probabilities[i]) for i, x in enumerate(tokens)])\n",
        "      sorted_tuple_list = sorted(tuple_list, key=lambda x: x[1], reverse=True)\n",
        "      print (text)\n",
        "      print (sorted_tuple_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQM01S_xVO5o",
        "outputId": "3994b58a-dfc5-4363-c636-b9dd3a83d315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "”I am the first to arrive.” She thought and came to her desk. She was surprised to find a bunch of flowers on it. They were fresh. She _ them and they were sweet. She looked around for a vase to put them in.\n",
            "[('smelled', 0.8809953), ('ate', 0.0591424), ('took', 0.053083885), ('held', 0.0067784367)]\n",
            "The most likely word is \"smelled\".\n"
          ]
        }
      ],
      "source": [
        "text = '”I am the first to arrive.” She thought and came to her desk.'\n",
        "text = text + ' She was surprised to find a bunch of flowers on it.'\n",
        "text = text + ' They were fresh. She _ them and they were sweet. She looked around for a vase to put them in.'\n",
        "candidates = ['smelled', 'ate', 'took', 'held']\n",
        "\n",
        "ask_BERT (text, candidates, language_model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8928msVZYb_n",
        "outputId": "dade9701-fba7-49a0-f077-24f0eafcf7bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nancy had just got a new job in a company.        Monday was the first day she went to work, so she         was very _ and arrived early.\n",
            "[('excited', 0.8247292), ('surprised', 0.14804865), ('encouraged', 0.021110376), ('depressed', 0.0061116396)]\n",
            "The most likely word is \"excited\".\n"
          ]
        }
      ],
      "source": [
        "text = 'Nancy had just got a new job in a company.\\\n",
        "        Monday was the first day she went to work, so she \\\n",
        "        was very _ and arrived early.'\n",
        "candidates = ['depressed', 'encouraged', 'excited', 'surprised']\n",
        "ask_BERT (text, candidates, language_model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4gO5a3HbEYW",
        "outputId": "e48d2cf2-d0be-4b48-ea85-45358685902e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nancy had just got a new job in a company.        Monday was the first day she went to work, so she         was very excited and arrived early. I am the _ to arrive.” She thought and came to her desk.\n",
            "[('first', 0.916222), ('last', 0.07019155), ('second', 0.011083992), ('third', 0.0025024929)]\n",
            "The most likely word is \"first\".\n"
          ]
        }
      ],
      "source": [
        "text = 'Nancy had just got a new job in a company.\\\n",
        "        Monday was the first day she went to work, so she \\\n",
        "        was very excited and arrived early.'\n",
        "text = text + ' I am the _ to arrive.” She thought and came to her desk.'\n",
        "candidates = ['last', 'second', 'third', 'first']\n",
        "ask_BERT (text, candidates, language_model, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13mIFjZaVO5p"
      },
      "source": [
        "For German, we need Multilingual BERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJY1DjsUVO5q",
        "outputId": "a45c1017-a83b-411a-ae7f-a76217954bbe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The pre-trained model you are loading is a cased model but you have not set `do_lower_case` to False. We are setting `do_lower_case=False` for you but you may want to check this behavior.\n",
            "100%|██████████| 995526/995526 [00:00<00:00, 1769855.51B/s]\n",
            "100%|██████████| 662804195/662804195 [00:40<00:00, 16261131.17B/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): BertLayerNorm()\n",
              "      )\n",
              "      (decoder): Linear(in_features=768, out_features=119547, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = 'bert-base-multilingual-cased'\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(model, do_lower_case=do_lower_case)\n",
        "language_model = BertForMaskedLM.from_pretrained(model)\n",
        "language_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLO2P2YodQyc",
        "outputId": "419312fc-8d6b-45a9-90d9-2ba757bd5346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wir gehen durch _ Wald.\n",
            "[('den', 0.85803), ('einen', 0.054593645), ('ein', 0.016730534), ('diesen', 0.015647667)]\n"
          ]
        }
      ],
      "source": [
        "text = 'Wir gehen durch _ Wald.'\n",
        "ask_BERT (text, [], language_model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZHHFSziVO5s",
        "outputId": "cabfc65a-30b8-41c7-f064-9c21720416c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Die Trophäe würde nicht in den braunen Koffer passen, weil _ zu groß sei.\n",
            "[('er', 0.38623446), ('sie', 0.20512679), ('es', 0.18469486), ('diese', 0.026795492), ('dieser', 0.017069455), ('man', 0.012291713)]\n"
          ]
        }
      ],
      "source": [
        "text = 'Die Trophäe würde nicht in den braunen Koffer passen, weil _ zu groß sei.'\n",
        "ask_BERT (text, [], language_model, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyuubRYoVO5t"
      },
      "source": [
        "Below you can find all the text used in the slides. Pass each string to *ask_BERT* to see whether Multilingual BERT knows enough about German grammar. Be sure to switch back to the monolingual model if you wish to use the English language examples below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLuKJiy_VO5t"
      },
      "outputs": [],
      "source": [
        "# German examples\n",
        "text = 'Bitte legen Sie es auf _ Schreibtisch.'\n",
        "text = 'Es ist auf _ Schreibtisch.'\n",
        "text = 'Wir gehen durch _ Wald.'\n",
        "text = 'Sie kommen aus _ Schweiz.'\n",
        "text = 'Ich ging trotz _ Erkältung zur Arbeit.'\n",
        "\n",
        "text = 'Die Trophäe würde nicht in den braunen Koffer passen, weil _ zu groß war.'\n",
        "text = 'Le trophée ne rentrait pas dans la valise marron parce qu\\'_ était trop grande.'\n",
        "text = 'The trophy would not fit in the brown suitcase because it was too big. What was too big, the trophy or the suitcase? The _.'\n",
        "\n",
        "text = 'Mark visited Janet\\'s grave in 1765. At that time, _ had been traveling for five years.'\n",
        "text = 'Mark visited Janet\\'s grave in 1765. Mark was alive, Janet was dead. At that time, _ had been traveling for five years.'\n",
        "\n",
        "text = 'Nancy had just got a new job in a company.\\\n",
        "        Monday was the first day she went to work, so she \\\n",
        "        was very _ and arrived early.'\n",
        "candidates = ['depressed', 'encouraged', 'excited', 'surprised']\n",
        "\n",
        "text = 'She _ the door open and found nobody there.'\n",
        "candidates = ['turned', 'pushed', 'knocked', 'forced']\n",
        "\n",
        "text = 'Ich ging trotz _ Erkältung zur Arbeit.'\n",
        "text = 'Ich träume von _ sprechenden Delphin.'\n",
        "text = 'Ich träume _, mit einem Delfin zu sprechen.'\n",
        "text = 'Die Trophäe würde nicht in den braunen Koffer passen, weil _ zu klein ist.'\n",
        "\n",
        "text = 'Mark visited Janet\\'s grave in 1765. At that time, _ had been dead for five years.'\n",
        "text = 'Janet had died. Mark visited Janet\\'s grave in 1765 (Janet had died). At that time, _ had been traveling for five years.'\n",
        "\n",
        "text = 'Die Trophäe würde nicht in den braunen Koffer passen, weil _ zu klein ist.'\n",
        "\n",
        "# English examples\n",
        "text = 'She _ the door open and found nobody there.'\n",
        "candidates = ['turned', 'pushed', 'knocked', 'forced']\n",
        "\n",
        "text = 'Mark visited Janet\\'s grave in 1765. Mark was alive, Janet was dead. At that time, _ had been traveling for five years.'\n",
        "candidates = []\n",
        "\n",
        "text = 'Nancy had just got a new job in a company.\\\n",
        "        Monday was the first day she went to work, so she \\\n",
        "        was very excited and arrived early.'\n",
        "candidates = ['depressed', 'encouraged', 'excited', 'surprised']\n",
        "text = ' She pushed the door open and found nobody there.'\n",
        "candidates = ['turned', 'pushed', 'knocked', 'forced']\n",
        "text = '”I am the _ to arrive.” She thought and came to her desk.'\n",
        "candidates = ['last', 'second', 'third', 'first']\n",
        "text = text + ' She was surprised to find a bunch of flowers on it.'\n",
        "text = text + ' They were fresh. She _ them and they were sweet. She looked around for a vase to put them in.'\n",
        "candidates = ['smelled', 'ate', 'took', 'held']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swIMrchkkjIh",
        "outputId": "60a98e4a-32be-4601-fa35-dd51a81d251f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bitte legen Sie es auf _ Schreibtisch.\n",
            "[('den', 0.5549784), ('dem', 0.18432878), ('einen', 0.09112396), ('einem', 0.087149836), ('der', 0.0155886095)]\n"
          ]
        }
      ],
      "source": [
        "text = 'Bitte legen Sie es auf _ Schreibtisch.'\n",
        "ask_BERT (text, [], language_model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q1KnudgFQTs",
        "outputId": "5f866c14-a8b3-4346-b20a-f937b3e9b71b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Die grössten Einbussen bei den Grossunternehmen gab es neben dem Personalvermittler Adecco bei _ Finanzwerten Partners Group, UBS und Julius Bär, die zeitweise zwischen 8 und 9 Prozent einbrachen.\n",
            "[('den', 0.9849413)]\n"
          ]
        }
      ],
      "source": [
        "text = 'Die grössten Einbussen bei den Grossunternehmen gab es neben dem Personalvermittler Adecco bei _ Finanzwerten Partners Group, UBS und Julius Bär, die zeitweise zwischen 8 und 9 Prozent einbrachen.'\n",
        "ask_BERT (text, [], language_model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAuNlp4qFfIv",
        "outputId": "fe5cf7a4-4b5e-43bd-a52e-d73747f633c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Die grössten Einbussen bei den Grossunternehmen gab es neben _ Personalvermittler Adecco bei den Finanzwerten Partners Group, UBS und Julius Bär, die zeitweise zwischen 8 und 9 Prozent einbrachen.\n",
            "[('dem', 0.92739695), ('der', 0.030345194), ('den', 0.02083853)]\n"
          ]
        }
      ],
      "source": [
        "text = 'Die grössten Einbussen bei den Grossunternehmen gab es neben _ Personalvermittler Adecco bei den Finanzwerten Partners Group, UBS und Julius Bär, die zeitweise zwischen 8 und 9 Prozent einbrachen.'\n",
        "ask_BERT (text, [], language_model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
