{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "from nltk.lm import MLE, Laplace\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import copy\n",
    "import random\n",
    "\n",
    "from transformers import pipeline\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = 'science_fiction'\n",
    "sentences = brown.sents(categories=genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Now', 'that', 'he', 'knew', 'himself', 'to', 'be', 'self', 'he', 'was', 'free', 'to', 'grok', 'ever', 'closer', 'to', 'his', 'brothers', ',', 'merge', 'without', 'let', '.']\n"
     ]
    }
   ],
   "source": [
    "print(list(sentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [[word.lower() for word in sentence] for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['now', 'that', 'he', 'knew', 'himself', 'to', 'be', 'self', 'he', 'was', 'free', 'to', 'grok', 'ever', 'closer', 'to', 'his', 'brothers', ',', 'merge', 'without', 'let', '.']\n"
     ]
    }
   ],
   "source": [
    "print(list(sentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amounts of tokens in the test set: 354\n"
     ]
    }
   ],
   "source": [
    "total_length = 0\n",
    "i = 0\n",
    "\n",
    "while total_length < 350:\n",
    "    total_length += len(sentences[i])\n",
    "    i += 1\n",
    "\n",
    "train_data = sentences[i:]\n",
    "test_data = sentences[:i]\n",
    "\n",
    "print(f'Total amounts of tokens in the test set: {total_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_sentence(sentence):\n",
    "    if len(sentence) < 1:\n",
    "        return sentence\n",
    "    \n",
    "    masked_sentence = sentence.copy()\n",
    "    mask_idx = random.randint(0, len(masked_sentence) - 1)\n",
    "    masked_sentence[mask_idx] = '[MASK]'\n",
    "    \n",
    "    return masked_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DISCLAIMER**\\\n",
    "The exercise states that every 7th word should be masked. However, distilBERT only masks one word per sentence.\\\n",
    "In order to compare the results of BLEU/ROUGE more accurately, we have changed the code to mask only one word for the ngram as well."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "for sentence in test_set_lm:\n",
    "    for idx in range(6, len(sentence), 7):\n",
    "        sentence[idx] = '[MASK]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_data = copy.deepcopy(test_data)\n",
    "\n",
    "for i, sentence in enumerate(test_data):\n",
    "    masked_sent = mask_sentence(sentence)\n",
    "    masked_data[i] = masked_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'data'\n",
    "\n",
    "if not os.path.exists(folder_name):\n",
    "      os.makedirs(folder_name)\n",
    "\n",
    "csv_file_path = os.path.join(folder_name, 'masked_sentences.csv')\n",
    "\n",
    "def save_masked_sents_to_csv(masked_sents, file_path):\n",
    "    with open(file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            for sentence in masked_sents:\n",
    "                writer.writerow(sentence)\n",
    "\n",
    "save_masked_sents_to_csv(masked_data, csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams = 3\n",
    "train_set_lm, vocab = padded_everygram_pipeline(n_grams, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocab before training: 0\n",
      "Length of vocab after training: 2993\n"
     ]
    }
   ],
   "source": [
    "lm = MLE(n_grams)\n",
    "print(f'Length of vocab before training: {len(lm.vocab)}')\n",
    "lm.fit(train_set_lm, vocab)\n",
    "print(f'Length of vocab after training: {len(lm.vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('in',\n",
       " 'his',\n",
       " 'mind',\n",
       " 'he',\n",
       " 'spoke',\n",
       " 'simultaneously',\n",
       " 'the',\n",
       " 'english',\n",
       " 'sentence',\n",
       " 'and',\n",
       " 'the',\n",
       " 'martian',\n",
       " 'word',\n",
       " 'and',\n",
       " 'felt',\n",
       " 'closer',\n",
       " 'grokking',\n",
       " '.')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.vocab.lookup(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<UNK>', 'it', '<UNK>')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.vocab.lookup(['stop', 'it', 'elmo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NgramCounter with 3 ngram orders and 50781 ngrams>\n"
     ]
    }
   ],
   "source": [
    "print(lm.counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0217"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(lm.score('mars', ['from']), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.5236"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(lm.logscore('mars', ['from']), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lady', \"''\", '?', '?', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.generate(10, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams_predictions(model, masked_sents):\n",
    "    predicted_sents = []\n",
    "\n",
    "    for sentence in masked_sents:\n",
    "        modified_sentence = []\n",
    "\n",
    "        for word in sentence:\n",
    "            if word == '[MASK]':\n",
    "                context = tuple(modified_sentence[-(model.order-1):])\n",
    "                predicted_word = model.generate(1, context)\n",
    "                modified_sentence.append(predicted_word)\n",
    "            else:\n",
    "                modified_sentence.append(word)\n",
    "\n",
    "        predicted_sents.append(modified_sentence)\n",
    "\n",
    "    return predicted_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sentences(masked_sents, pred_sents, original_sents):\n",
    "    for i in range(2):\n",
    "        print(f'Masked sentence:\\n{' '.join(masked_sents[i])}')\n",
    "        print(f'Predicted sentence:\\n{' '.join(pred_sents[i])}')\n",
    "        print(f'Original sentence:\\n{' '.join(original_sents[i])}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked sentence:\n",
      "now that he knew himself to be self he was free to grok ever closer to his brothers , merge [MASK] let .\n",
      "Predicted sentence:\n",
      "now that he knew himself to be self he was free to grok ever closer to his brothers , merge out let .\n",
      "Original sentence:\n",
      "now that he knew himself to be self he was free to grok ever closer to his brothers , merge without let .\n",
      "\n",
      "Masked sentence:\n",
      "self's [MASK] was and is and ever had been .\n",
      "Predicted sentence:\n",
      "self's '' was and is and ever had been .\n",
      "Original sentence:\n",
      "self's integrity was and is and ever had been .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_sents_ngram = ngrams_predictions(lm, masked_data)\n",
    "compare_sentences(masked_data, pred_sents_ngram, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "model = pipeline('fill-mask', model='distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_predictions(model, masked_data):\n",
    "    predicted_sents = []\n",
    "\n",
    "    for sentence in masked_data:        \n",
    "        sentence_str = ' '.join(sentence)\n",
    "        \n",
    "        try:\n",
    "            output = model(sentence_str)\n",
    "            y_pred = output[0]['sequence']\n",
    "\n",
    "            predicted_sents.append(y_pred.split())\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f'Error processing sentence: {e}\\n')\n",
    "    \n",
    "    return predicted_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked sentence:\n",
      "now that he knew himself to be self he was free to grok ever closer to his brothers , merge [MASK] let .\n",
      "Predicted sentence:\n",
      "now that he knew himself to be self he was free to grok ever closer to his brothers, merge and let.\n",
      "Original sentence:\n",
      "now that he knew himself to be self he was free to grok ever closer to his brothers , merge without let .\n",
      "\n",
      "Masked sentence:\n",
      "self's [MASK] was and is and ever had been .\n",
      "Predicted sentence:\n",
      "self ' s heart was and is and ever had been.\n",
      "Original sentence:\n",
      "self's integrity was and is and ever had been .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_sents_bert = bert_predictions(model, masked_data)\n",
    "compare_sentences(masked_data, pred_sents_bert, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked sentence:\n",
      "now that he knew himself to be self he was free to grok ever closer to his brothers , merge [MASK] let .\n",
      "Predicted sentence:\n",
      "now that he knew himself to be self he was free to grok ever closer to his brothers , merge is let .\n",
      "Original sentence:\n",
      "now that he knew himself to be self he was free to grok ever closer to his brothers , merge without let .\n",
      "\n",
      "Masked sentence:\n",
      "self's [MASK] was and is and ever had been .\n",
      "Predicted sentence:\n",
      "self's always was and is and ever had been .\n",
      "Original sentence:\n",
      "self's integrity was and is and ever had been .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_and_clean_predictions(csv_file):\n",
    "    pred_sents_friend = []\n",
    "\n",
    "    with open(csv_file, mode='r', encoding='utf-8-sig') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            cleaned_row = [word for word in row if word.strip() != '']\n",
    "            pred_sents_friend.append(cleaned_row)\n",
    "    \n",
    "    return pred_sents_friend\n",
    "\n",
    "pred_sents_friend = load_and_clean_predictions('data/pred_sents_friend.csv')\n",
    "compare_sentences(masked_data, pred_sents_friend, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bleu_score(predicted_sents, original_sents):\n",
    "    scores = []\n",
    "\n",
    "    for pred, ref in zip(predicted_sents, original_sents):\n",
    "        score = sentence_bleu([ref], pred, smoothing_function=smoothie)\n",
    "        scores.append(score)\n",
    "    \n",
    "    return sum(scores) / len(scores)\n",
    "\n",
    "smoothie = SmoothingFunction().method4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rouge_scores(predicted_sents, original_sents):\n",
    "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"])\n",
    "\n",
    "    rouge1_score = 0\n",
    "    rouge2_score = 0\n",
    "    rougeL_score = 0\n",
    "\n",
    "    for pred, ref in zip(predicted_sents, original_sents):\n",
    "        score = scorer.score(' '.join(ref), ' '.join(pred))\n",
    "\n",
    "        rouge1_score += score['rouge1'].fmeasure\n",
    "        rouge2_score += score['rouge2'].fmeasure\n",
    "        rougeL_score += score['rougeL'].fmeasure\n",
    "        \n",
    "    num_sents = len(original_sents)\n",
    "\n",
    "    rouge1_score /= num_sents\n",
    "    rouge2_score /= num_sents\n",
    "    rougeL_score /= num_sents\n",
    "    \n",
    "    return [rouge1_score, rouge2_score, rougeL_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_score_ngram = compute_bleu_score(pred_sents_ngram, masked_data)\n",
    "bleu_score_bert = compute_bleu_score(pred_sents_bert, masked_data)\n",
    "bleu_score_friend = compute_bleu_score(pred_sents_friend, masked_data)\n",
    "\n",
    "rouge_scores_ngram = compute_rouge_scores(pred_sents_ngram, masked_data)\n",
    "rouge_scores_bert = compute_rouge_scores(pred_sents_bert, masked_data)\n",
    "rouge_scores_friend = compute_rouge_scores(pred_sents_friend, masked_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU scores\n",
      "---------------------\n",
      "BLEU\n",
      "ngram: 0.8704\n",
      "bert: 0.5794\n",
      "human: 0.8704\n",
      "\n",
      "Average ROUGE scores\n",
      "---------------------\n",
      "ROUGE-1\n",
      "ngram: 0.9511\n",
      "bert: 0.9417\n",
      "human: 0.9244\n",
      "ROUGE-2\n",
      "ngram: 0.9049\n",
      "bert: 0.8957\n",
      "human: 0.8744\n",
      "ROUGE-L\n",
      "ngram: 0.9511\n",
      "bert: 0.9417\n",
      "human: 0.9244\n"
     ]
    }
   ],
   "source": [
    "print(f'Average BLEU scores')\n",
    "print('---------------------')\n",
    "print(f'BLEU\\nngram: {bleu_score_ngram:.4f}\\nbert: {bleu_score_bert:.4f}\\nhuman: {bleu_score_friend:.4f}')\n",
    "print()\n",
    "print(f'Average ROUGE scores')\n",
    "print('---------------------')\n",
    "print(f'ROUGE-1\\nngram: {rouge_scores_ngram[0]:.4f}\\nbert: {rouge_scores_bert[0]:.4f}\\nhuman: {rouge_scores_friend[0]:.4f}')\n",
    "print(f'ROUGE-2\\nngram: {rouge_scores_ngram[1]:.4f}\\nbert: {rouge_scores_bert[1]:.4f}\\nhuman: {rouge_scores_friend[1]:.4f}')\n",
    "print(f'ROUGE-L\\nngram: {rouge_scores_ngram[2]:.4f}\\nbert: {rouge_scores_bert[2]:.4f}\\nhuman: {rouge_scores_friend[2]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
